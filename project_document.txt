            +--------------------+
                     |    CS 140    |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+

---- GROUP ----

Taejun Han(20201322_한태준) <cheld7132@unist.ac.kr>
Eungyeong Baek(20211143 백은경) <ekbaek@unist.ac.kr>


---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In "struct thread" in "thread.h",
we add "int64_t wakeup_tick" as struct member variable. 
It stores the tick count at which a sleeping thread should be awakened, 
facilitating time-specific sleep management in the scheduler.

In "thread.c",
we declare "static struct list sleep_list" as the static variable.
A list that stores all threads currently in the sleep state, 
enabling efficient tracking and management of threads that need to be woken up.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

When the time_sleep() function is called, it facilitates pausing the calling thread for a specified number of timer ticks.

The timer_sleep() function is started by calling timer_ticks(), which returns the current number of ticks since the system started. 
Then, thread_sleep(start + ticks) is executed.
At this time, “start + ticks” means the time when the sleeping thread will wake up.

Within this thread_sleep(start + ticks), several key tasks occur.
First of all, operations must be performed atomically to prevent race conditions. 
Therefore, disable interrupts. And we use thread_current() to retrieve the current thread. 
If this current thread is not an idle thread, then this current thread is added to sleep_list. 
And changes the state of the caller thread to BLOCKED. 
And the wakeup time of the sleeping thread is stored in the wakeup_tick property of the current thread structure. 
Finally, interrupts are re-enabled to their original state.

At this time, through the timer interrupt handler, the ticks value increases each time the timer is interrupted. 
This handler also iteratively checks each thread's sleep_list to see if its current tick count has reached or exceeded the thread's wakeup_tick. 
For any thread whose time has come to finally wake up, the handler removes that thread from its sleep_list and changes its state from BLOCKED to READY, effectively scheduling its execution.

This implementation utilizes a timer interrupt handler to periodically check and wake up the thread when the specified sleep period has elapsed, 
ensuring that timer_sleep() efficiently places the calling thread into a non-busy waiting state. 
This mechanism is important for optimizing CPU usage and enabling effective multitasking within the operating system.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

In the implementation of thread_awake within the timer_interrupt handler, the system employs a sorted list by each thread's wakeup_tick. 
This arrangement allows the thread_awake function to iterate through the sleep_list only until it encounters a thread whose wakeup_tick is greater than the current ticks. 
This is crucial because once a wakeup_tick that exceeds the current ticks is found, the function can cease its iteration early, 
ensuring that no unnecessary checks are made against threads that do not need to be woken up yet.

This method significantly reduces the time spent processing each timer interrupt 
because it avoids needless traversal of the entire list and focuses only on those threads that are due to wake up. 

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

The first time you call timer_sleep(), thread_sleep is called. At this time, thread_sleep() disables interrupts. 
Disabling interrupts creates an atomic operation because no other thread or interrupt handler can interrupt the process.

Second, within this critical section, the current thread is added to the sleep list, the wakeup tick is stored, and the current thread is blocked. 
At this time, this critical section must be processed all at once without interruption.

Eventually, the thread becomes blocked through a thread_block() call. 
This function transitions a thread from the running state to the non-executable (blocked) state without requiring any CPU resources until the wake-up condition is met. 
By blocking threads within the same critical section with interrupts disabled, we ensure that threads do not continue executing in a potentially inconsistent state or with shared data.

Finally, the original interrupt level is restored after the thread is safely added to the sleep_list and its state is set to blocked. 
This operation re-enables interrupts, allowing execution of other threads and interrupt handlers. 
Now that the important modifications have been made and the current thread is blocked, you are safe.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

in struct thread
(1) struct lock *wait_on_lock;
-purpose: For nested donation, wait_on_lock acts as an intermediary between threads. 
ex)  thread A <-(holder) lockA <- (wait_on_lock)  <- thread B <-(holder) lockB (wait_on_lock) <- thread C        

(2) struct list donations;
-purpose: Through this list, when one of multiple locks is released, the priorities are compared and donated again with the highest priority.

(3) struct list_elem d_elem;
-purpose: list_elem for donations list           

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
(1) sema_down
In the sema_down function, putting things into the waiter list through list_push_back was changed to be 
in descending order based on the priority of the thread through the list_inserted_ordered function.

(2) sema_up
By sorting the waiter list before thread_unblock, it covers cases where the priorities of threads may have changed in the waiter list.
And since front has the highest priority in the descending waiter list, when sema_up wake up thread,
front is taken out and removed at the same time through the list_pop_front function.

(3) cond_wait and cond_signal
An algorithm similar to (1) and (2) is used.
The difference is that the semaphore puts a thread structure in the waiter list, but the condition variable puts a semaphore_elem structure.
So the cmp function used is different.
cmp_priority can directly compare thread's priority through list_entry,
but cmp_cond_priority have to compare thread's priority through  semaphore.watiers, a member of semphore_elem, as a parameter of list_front

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
If the lock's holder has a lower priority than the thread that currently called the lock_acquire() function,
the caller donates priority to the holder.
The maximum value of nested is set to 10, so the for statement is run a maximum of 10 times.
At this time, access(iteration) is made through the wait_on_lock variable in order to donate to the threads nesting the lock.
ex) l(wait_on_lock)->holder->priority = cur->priority  and next => l = l->holder->wait_on_lock and if l == NULL mean front thread in nested donation
In nested donations, the thread that always performs lock_acquire() last will inevitably have a higher priority than the thread in front of it.
This is because the thread at the front always receives the donation, but the fact that another thread is allocated the CPU means that a thread with a higher priority than this priority has locked_aquire even though it has received the donation.
>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?